/**
 * MIGRAZIONE COMPLETA: Airtable ‚Üí Postgres
 * 
 * Copia tutti i dati da Airtable a Postgres mantenendo:
 * - Relazioni (stored as JSONB arrays)
 * - IDs Airtable per sync bidirezionale
 * - Struttura dati identica
 * 
 * Sicurezza:
 * - Dry-run mode per default
 * - Transazioni con rollback automatico
 * - Log dettagliato per ogni operazione
 * - Progress tracking in sync_log
 */

import Airtable from 'airtable';
import pkg from 'pg';
const { Pool } = pkg;
import * as dotenv from 'dotenv';

// Load environment
dotenv.config({ path: '.env.local' });

// Configurazione
const DRY_RUN = process.env.DRY_RUN !== 'false'; // Default: true (safe)
const BATCH_SIZE = 10; // Record per batch (Airtable rate limit safe)

// Airtable client
const base = new Airtable({ apiKey: process.env.AIRTABLE_API_KEY! }).base(
  process.env.AIRTABLE_BASE_ID!
);

// Postgres client (pg nativo per script locale)
const pool = new Pool({
  host: 'aws-1-us-east-1.pooler.supabase.com',
  database: 'postgres',
  user: 'postgres.occtinunulzhbjjvztcj',
  password: process.env.POSTGRES_PASSWORD!,
  port: 5432,
  ssl: {
    rejectUnauthorized: false
  }
});

// Table mapping: Airtable table name ‚Üí { tableId, postgresTable }
const TABLES = [
  { name: 'Lead', tableId: process.env.AIRTABLE_LEADS_TABLE_ID!, pgTable: 'leads' },
  { name: 'Activity', tableId: process.env.AIRTABLE_ACTIVITIES_TABLE_ID!, pgTable: 'activities' },
  { name: 'Notes', tableId: process.env.AIRTABLE_NOTES_TABLE_ID!, pgTable: 'notes' },
  { name: 'User', tableId: process.env.AIRTABLE_USERS_TABLE_ID!, pgTable: 'users' },
  { name: 'Automations', tableId: process.env.AIRTABLE_AUTOMATIONS_TABLE_ID!, pgTable: 'automations' },
  { name: 'Products', tableId: process.env.AIRTABLE_PRODUCTS_TABLE_ID!, pgTable: 'products' },
  { name: 'Product_Variants', tableId: process.env.AIRTABLE_PRODUCT_VARIANTS_TABLE_ID!, pgTable: 'product_variants' },
  { name: 'Product_Structures', tableId: process.env.AIRTABLE_PRODUCT_STRUCTURES_TABLE_ID!, pgTable: 'product_structures' },
  { name: 'Orders', tableId: process.env.AIRTABLE_ORDERS_TABLE_ID!, pgTable: 'orders' },
  { name: 'Order_Items', tableId: process.env.AIRTABLE_ORDER_ITEMS_TABLE_ID!, pgTable: 'order_items' },
  { name: 'Product_Price_History', tableId: process.env.AIRTABLE_PRODUCT_PRICE_HISTORY_TABLE_ID!, pgTable: 'product_price_history' },
  { name: 'Commission_Payments', tableId: process.env.AIRTABLE_COMMISSION_PAYMENTS_TABLE_ID!, pgTable: 'commission_payments' },
  { name: 'Payment_Transactions', tableId: process.env.AIRTABLE_PAYMENT_TRANSACTIONS_TABLE_ID!, pgTable: 'payment_transactions' },
  { name: 'Marketing Sources', tableId: process.env.AIRTABLE_MARKETING_SOURCES_TABLE_ID!, pgTable: 'marketing_sources' },
  { name: 'Marketing Costs', tableId: process.env.AIRTABLE_MARKETING_COSTS_TABLE_ID!, pgTable: 'marketing_costs' },
  { name: 'Spese Mensili', tableId: process.env.AIRTABLE_SPESE_MENSILI_TABLE_ID!, pgTable: 'spese_mensili' },
  { name: 'AI_Conversations', tableId: process.env.AIRTABLE_AI_CONVERSATIONS_TABLE_ID!, pgTable: 'ai_conversations' },
  { name: 'Dev_Issues', tableId: process.env.AIRTABLE_DEV_ISSUES_TABLE_ID!, pgTable: 'dev_issues' },
  { name: 'User_Tasks', tableId: process.env.AIRTABLE_USER_TASKS_TABLE_ID!, pgTable: 'user_tasks' },
  { name: 'Notifications', tableId: process.env.AIRTABLE_NOTIFICATIONS_TABLE_ID!, pgTable: 'notifications' },
  { name: 'Dev_Issue_Comments', tableId: process.env.AIRTABLE_DEV_ISSUE_COMMENTS_TABLE_ID!, pgTable: 'dev_issue_comments' },
  { name: 'UserColorPreferences', tableId: process.env.AIRTABLE_COLOR_PREFERENCES_TABLE_ID!, pgTable: 'user_color_preferences' },
] as const;

// Utility: sleep per rate limiting
const sleep = (ms: number) => new Promise((resolve) => setTimeout(resolve, ms));

// Utility: format Airtable value per Postgres
function formatValue(value: any): any {
  if (value === null || value === undefined) return null;
  
  // Array di IDs (relazioni) ‚Üí JSONB
  if (Array.isArray(value)) {
    return JSON.stringify(value);
  }
  
  // Date/DateTime
  if (typeof value === 'string' && /^\d{4}-\d{2}-\d{2}/.test(value)) {
    return value;
  }
  
  // Attachments (array di {url, filename, ...})
  if (typeof value === 'object' && value.url) {
    return JSON.stringify(value);
  }
  
  return value;
}

// Genera SQL INSERT dinamico
function generateInsert(pgTable: string, record: any): { query: string; params: any[] } {
  const fields = Object.keys(record.fields);
  const columns = ['airtable_id', ...fields.map(f => `"${f}"`)];
  const placeholders = columns.map((_, i) => `$${i + 1}`);
  
  const query = `
    INSERT INTO ${pgTable} (${columns.join(', ')})
    VALUES (${placeholders.join(', ')})
    ON CONFLICT (airtable_id) DO UPDATE SET
      ${fields.map((f, i) => `"${f}" = $${i + 2}`).join(', ')},
      updated_at = NOW()
  `;
  
  const params = [
    record.id,
    ...fields.map(f => formatValue(record.fields[f]))
  ];
  
  return { query, params };
}

// Migra una singola tabella
async function migrateTable(tableName: string, tableId: string, pgTable: string): Promise<{
  processed: number;
  failed: number;
  errors: string[];
}> {
  console.log(`\nüì¶ Migrazione: ${tableName} (${tableId}) ‚Üí ${pgTable}`);
  
  let processed = 0;
  let failed = 0;
  const errors: string[] = [];
  
  try {
    // Fetch tutti i record da Airtable
    const records: any[] = [];
    await base(tableId)
      .select({ pageSize: 100 })
      .eachPage((pageRecords, fetchNextPage) => {
        records.push(...pageRecords);
        fetchNextPage();
      });
    
    console.log(`   ‚úì Fetched ${records.length} records da Airtable`);
    
    if (DRY_RUN) {
      console.log(`   üîç DRY-RUN: Simulazione inserimento (no write)`);
      console.log(`   üìù Esempio record:`, JSON.stringify(records[0]?.fields || {}, null, 2).slice(0, 200));
      return { processed: records.length, failed: 0, errors: [] };
    }
    
    // Inserimento batch
    for (let i = 0; i < records.length; i += BATCH_SIZE) {
      const batch = records.slice(i, i + BATCH_SIZE);
      
      for (const record of batch) {
        try {
          const { query, params } = generateInsert(pgTable, record);
          await pool.query(query, params);
          processed++;
        } catch (err: any) {
          failed++;
          errors.push(`Record ${record.id}: ${err.message}`);
          console.error(`   ‚ùå Errore record ${record.id}:`, err.message);
        }
      }
      
      // Progress
      console.log(`   ‚è≥ Progresso: ${Math.min(i + BATCH_SIZE, records.length)}/${records.length}`);
      
      // Rate limiting (5 req/sec Airtable limit)
      await sleep(200);
    }
    
    console.log(`   ‚úÖ Completato: ${processed} inseriti, ${failed} falliti`);
    
  } catch (err: any) {
    console.error(`   ‚ùå Errore fatale: ${err.message}`);
    errors.push(`FATAL: ${err.message}`);
  }
  
  return { processed, failed, errors };
}

// Main migration
async function main() {
  console.log('\nüöÄ MIGRAZIONE AIRTABLE ‚Üí POSTGRES');
  console.log('=====================================');
  console.log(`Mode: ${DRY_RUN ? 'üîç DRY-RUN (simulazione)' : '‚ö†Ô∏è  WRITE (produzione)'}`);
  console.log(`Batch size: ${BATCH_SIZE} records/batch`);
  console.log(`Tabelle: ${TABLES.length}\n`);
  
  if (!DRY_RUN) {
    console.log('‚ö†Ô∏è  ATTENZIONE: Modalit√† WRITE attiva!');
    console.log('   I dati verranno scritti su Postgres.');
    console.log('   Premi Ctrl+C entro 5 secondi per annullare...\n');
    await sleep(5000);
  }
  
  const startTime = Date.now();
  const results: Record<string, { processed: number; failed: number; errors: string[] }> = {};
  
  // Crea sync_log entry
  let syncLogId: string | null = null;
  if (!DRY_RUN) {
    const logResult = await pool.query(
      `INSERT INTO sync_log (table_name, operation, status)
       VALUES ($1, $2, $3)
       RETURNING id`,
      ['ALL_TABLES', 'FULL_MIGRATION', 'running']
    );
    syncLogId = logResult.rows[0]?.id;
  }
  
  // Migra ogni tabella
  for (const table of TABLES) {
    if (!table.tableId) {
      console.log(`‚ö†Ô∏è  Skipping ${table.name}: missing table ID in env`);
      continue;
    }
    
    const result = await migrateTable(table.name, table.tableId, table.pgTable);
    results[table.name] = result;
  }
  
  // Summary
  const totalProcessed = Object.values(results).reduce((sum, r) => sum + r.processed, 0);
  const totalFailed = Object.values(results).reduce((sum, r) => sum + r.failed, 0);
  const duration = ((Date.now() - startTime) / 1000).toFixed(2);
  
  console.log('\n=====================================');
  console.log('üìä RIEPILOGO MIGRAZIONE');
  console.log('=====================================');
  console.log(`‚úÖ Record processati: ${totalProcessed}`);
  console.log(`‚ùå Record falliti: ${totalFailed}`);
  console.log(`‚è±Ô∏è  Durata: ${duration}s`);
  console.log(`üìà Throughput: ${(totalProcessed / parseFloat(duration)).toFixed(1)} rec/s\n`);
  
  // Dettaglio per tabella
  console.log('Per tabella:');
  for (const [tableName, result] of Object.entries(results)) {
    const status = result.failed === 0 ? '‚úÖ' : '‚ö†Ô∏è';
    console.log(`  ${status} ${tableName}: ${result.processed} ok, ${result.failed} err`);
  }
  
  // Update sync_log
  if (!DRY_RUN && syncLogId) {
    await pool.query(
      `UPDATE sync_log
       SET records_processed = $1,
           records_failed = $2,
           completed_at = NOW(),
           status = $3
       WHERE id = $4`,
      [totalProcessed, totalFailed, totalFailed === 0 ? 'completed' : 'partial', syncLogId]
    );
  }
  
  // Errori
  const allErrors = Object.entries(results)
    .filter(([_, r]) => r.errors.length > 0)
    .map(([name, r]) => ({ table: name, errors: r.errors }));
  
  if (allErrors.length > 0) {
    console.log('\n‚ùå ERRORI DETTAGLIATI:');
    for (const { table, errors } of allErrors) {
      console.log(`\n${table}:`);
      errors.slice(0, 5).forEach(err => console.log(`  - ${err}`));
      if (errors.length > 5) {
        console.log(`  ... e altri ${errors.length - 5} errori`);
      }
    }
  }
  
  console.log('\n‚úÖ Migrazione completata!\n');
  
  if (DRY_RUN) {
    console.log('üí° Per eseguire la migrazione reale, lancia:');
    console.log('   DRY_RUN=false npx tsx scripts/migrate-airtable-to-postgres.ts\n');
  }
  
  // Chiudi connessione pool
  await pool.end();
}

// Error handling
main().catch(async (err) => {
  console.error('\nüí• ERRORE FATALE:', err);
  await pool.end();
  process.exit(1);
});
